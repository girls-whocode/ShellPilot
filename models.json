[
    {
        "id": "phi-3.1-mini-q4",
        "name": "Phi 3.1 Mini (Q4_K_M)",
        "description": "Ultra-small and extremely fast. Perfect fallback for tiny machines.",
        "subdir": "phi-3.1-mini",
        "filename": "Phi-3.1-mini-instruct-Q4_K_M.gguf",
        "download_url": "https://huggingface.co/microsoft/phi-3.1-mini-instruct-gguf/resolve/main/phi-3.1-mini-instruct-q4_k_m.gguf",
        "recommended_ram_gb": 3
    },
    {
        "id": "phi-3.5-mini-q4",
        "name": "Phi 3.5 Mini (Q4_K_M)",
        "description": "Fast and lightweight. Ideal for slower CPUs and small VPS systems.",
        "subdir": "phi-3.5-mini",
        "filename": "Phi-3.5-mini-instruct-Q4_K_M.gguf",
        "download_url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-Q4_K_M.gguf",
        "recommended_ram_gb": 4
    },
    {
        "id": "qwen2.5-1.5b-q4",
        "name": "Qwen2.5 1.5B Instruct (Q4_K_M)",
        "description": "Ridiculously strong for its size. Superb reasoning.",
        "subdir": "qwen2.5-1.5b",
        "filename": "qwen2.5-1.5b-instruct-q4_k_m.gguf",
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf",
        "recommended_ram_gb": 6
    },
    {
        "id": "phi-3.5-small-q4",
        "name": "Phi 3.5 Small (Q4_K_M)",
        "description": "Stronger reasoning than Mini; still fast on laptops.",
        "subdir": "phi-3.5-small",
        "filename": "Phi-3.5-small-instruct-Q4_K_M.gguf",
        "download_url": "https://huggingface.co/microsoft/Phi-3.5-small-instruct-gguf/resolve/main/Phi-3.5-small-instruct-Q4_K_M.gguf",
        "recommended_ram_gb": 8
    },
    {
        "id": "qwen2.5-3b-q4",
        "name": "Qwen2.5 3B Instruct (Q4_K_M)",
        "description": "Strong mid-range model; excellent understanding of Linux tooling.",
        "subdir": "qwen2.5-3b",
        "filename": "qwen2.5-3b-instruct-q4_k_m.gguf",
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q4_k_m.gguf",
        "recommended_ram_gb": 10
    },
    {
        "id": "mistral-7b-q4",
        "name": "Mistral 7B Instruct (Q4_K_M)",
        "description": "Former gold-standard 7B model. Still excellent for general tasks.",
        "subdir": "mistral-7b",
        "filename": "mistral-7b-instruct-v0.3-q4_k_m.gguf",
        "download_url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3-q4_k_m.gguf",
        "recommended_ram_gb": 10
    },
    {
        "id": "qwen2.5-7b-q4",
        "name": "Qwen2.5 7B Instruct (Q4_K_M)",
        "description": "High-performance 7B model with excellent reasoning.",
        "subdir": "qwen2.5-7b",
        "filename": "qwen2.5-7b-instruct-q4_k_m.gguf",
        "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf",
        "recommended_ram_gb": 16
    },
    {
        "id": "llama-3.1-8b-q4",
        "name": "Llama 3.1 8B Instruct (Q4_K_M)",
        "description": "Meta's new-generation 8B model; powerful and accurate.",
        "subdir": "llama-3.1-8b",
        "filename": "Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "download_url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Llama-3.1-8B-Instruct-Q4_K_M.gguf",
        "recommended_ram_gb": 18
    },
    {
        "id": "dolphin-8b-q4",
        "name": "Dolphin 2.9 (Llama3 8B, Q4_K_M)",
        "description": "Heavily fine-tuned Llama3 8B for tool-use and structured responses.",
        "subdir": "dolphin-8b",
        "filename": "dolphin-2.9-llama3-8b-q4_k_m.gguf",
        "download_url": "https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b-gguf/resolve/main/dolphin-2.9-llama3-8b-q4_k_m.gguf",
        "recommended_ram_gb": 20
    },
    {
        "id": "llama-3.1-70b-q4",
        "name": "Llama 3.1 70B (Q4_K_M)",
        "description": "Massive 70B model for extreme reasoning. Not for most users.",
        "subdir": "llama-3.1-70b",
        "filename": "Llama-3.1-70B-Instruct-Q4_K_M.gguf",
        "download_url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Llama-3.1-70B-Instruct-Q4_K_M.gguf",
        "recommended_ram_gb": 40
    }
]