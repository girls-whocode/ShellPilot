[
  {
    "id": "phi-3.1-mini-q4",
    "name": "Phi-3 Mini 4K Instruct (Q4_K_M)",
    "description": "Tiny but surprisingly strong. Great baseline for very small machines.",
    "subdir": "phi-3-mini-4k",
    "filename": "Phi-3-mini-4k-instruct-Q4_K_M.gguf",
    "download_url": "https://huggingface.co/bartowski/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q4_K_M.gguf",
    "recommended_ram_gb": 3
  },
  {
    "id": "phi-3.5-mini-q4",
    "name": "Phi-3.5 Mini (Q4_K_M)",
    "description": "Fast, small and very solid reasoning. Good default for laptops/VMs.",
    "subdir": "phi-3.5-mini",
    "filename": "Phi-3.5-mini-instruct-Q4_K_M.gguf",
    "download_url": "https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q4_K_M.gguf",
    "recommended_ram_gb": 4
  },
  {
    "id": "qwen2.5-1.5b-q4",
    "name": "Qwen2.5 1.5B Instruct (Q4_K_M)",
    "description": "Ridiculously strong 1.5B model. Great reasoning for its size.",
    "subdir": "qwen2.5-1.5b",
    "filename": "qwen2.5-1.5b-instruct-q4_k_m.gguf",
    "download_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf",
    "recommended_ram_gb": 6
  },
  {
    "id": "phi-3.5-small-q4",
    "name": "Phi-3.5 Small (IQ4_XS)",
    "description": "Unofficial IQ4_XS quant of Phi-3.5 Small. More capable than Mini, still compact.",
    "subdir": "phi-3.5-small",
    "filename": "Phi-3.5-Small-Instruct-UNOFFICAL.IQ4_XS.gguf",
    "download_url": "https://huggingface.co/mradermacher/Phi-3.5-Small-Instruct-UNOFFICAL-GGUF/resolve/main/Phi-3.5-Small-Instruct-UNOFFICAL.IQ4_XS.gguf",
    "recommended_ram_gb": 8
  },
  {
    "id": "qwen2.5-3b-q4",
    "name": "Qwen2.5 3B Instruct (Q4_K_M)",
    "description": "Excellent mid-size model. Very good for coding/sysadmin tasks.",
    "subdir": "qwen2.5-3b",
    "filename": "qwen2.5-3b-instruct-q4_k_m.gguf",
    "download_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q4_k_m.gguf",
    "recommended_ram_gb": 10
  },
  {
    "id": "mistral-7b-q4",
    "name": "Mistral 7B Instruct v0.3 (Q4_K_M)",
    "description": "Classic 7B workhorse; good general assistant and code model.",
    "subdir": "mistral-7b",
    "filename": "mistral-7b-instruct-v0.3-q4_k_m-imat.gguf",
    "download_url": "https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3-q4_k_m-imat.gguf",
    "recommended_ram_gb": 10
  },
  {
    "id": "qwen2.5-7b-q4",
    "name": "Qwen2.5 7B Instruct (Q4_K_M)",
    "description": "High-performance 7B with great reasoning and coding ability.",
    "subdir": "qwen2.5-7b",
    "filename": "qwen2.5-7b-instruct-q4_k_m.gguf",
    "download_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf",
    "recommended_ram_gb": 16
  },
  {
    "id": "llama-3.1-8b-q4",
    "name": "Llama 3.1 8B Instruct (Q4_K_M)",
    "description": "Metaâ€™s strong 8B instruct model. Great generalist if you have the RAM.",
    "subdir": "llama-3.1-8b",
    "filename": "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
    "download_url": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
    "recommended_ram_gb": 18
  },
  {
    "id": "dolphin-8b-q4",
    "name": "Dolphin 2.9 (Llama3 8B, Q4_K_M)",
    "description": "Chatty Llama-3-based 8B tuned for tools and structured outputs.",
    "subdir": "dolphin-8b",
    "filename": "dolphin-2.9-llama3-8b-q4_k_m.gguf",
    "download_url": "https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b-gguf/resolve/main/dolphin-2.9-llama3-8b-q4_k_m.gguf",
    "recommended_ram_gb": 20
  },
  {
    "id": "llama-3.1-70b-q4",
    "name": "Llama 3.1 70B Instruct (Q4_K_M)",
    "description": "Absurdly big brain. Only for monster boxes, but ShellPilot will happily drive it.",
    "subdir": "llama-3.1-70b",
    "filename": "Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf",
    "download_url": "https://huggingface.co/bartowski/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf",
    "recommended_ram_gb": 40
  }
]
